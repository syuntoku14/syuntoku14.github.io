[{"authors":null,"categories":null,"content":"I am a Ph.D. candidate at The University of Tokyo in Japan (2022-). My research interests include reinforcement learning theory, bandit algorithms, deep learning, and robotics.\n  Download my resumé.\n","date":1645747200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1645747200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Ph.D. candidate at The University of Tokyo in Japan (2022-). My research interests include reinforcement learning theory, bandit algorithms, deep learning, and robotics.\n  Download my resumé.","tags":null,"title":"Toshinori Kitamura","type":"authors"},{"authors":["Toshinori Kitamura"],"categories":["Internship"],"content":"2021年6月から2022年2月まで, オムロンサイニックエックス (OSX) にて研究インターンをさせていただきました. これはOSXインターンについてまとめたポストになります. 元インターンの奥村さんのポストも参考になるのでぜひ.\n自己紹介  現在は奈良先端科学技術大学院大学の修士２年, 2022年の4月から東京大学で博士課程に進学予定の学生です. 学部の頃はロボットよりの研究をしていましたが, 修士課程では強化学習の理論やアルゴリズムがメインの研究をやっていました. 詳しくはホームページを見てね.  インターンまでの経緯 M2の前半で主著を1つ \u0026amp; 共著を2つ生やすことができたので, M2の後半はインターンやりたいなあ〜って思っていたところ, 研究室経由でメンターの米谷さんからOSXインターンのお誘いをいただきました. 待遇や時期的にもかなり好条件だったので即返事をし, フルタイムで半年以上の研究インターンに参加させていただきました. インターンへの応募はここに詳細があります.\n何をやったのか 強化学習の理論と応用の実験をサポートしたライブラリ ShinRL を開発しました. 当初は米谷さんの提案でオフライン強化学習のテーマに取り組んでおり, 僕が個人的に開発していたShinRLを使ってデバッグ \u0026amp; アルゴリズムの実装を進めていました. もっとShinRLを高速化したい, 実装をキレイにしたい, などの理由で途中からShinRLの開発にシフトし始め, 最終的にはOSXとしてオフィシャルに公開するのを目標にテーマを変更しました (米谷さんは快く承諾していただきました. 圧倒的感謝).\n当初はPyTorchで実装していたShinRLですが, 速度面や実装の単純さ, 勉強目的からJAXを利用して実装することに (米谷さんとJAXの勉強ができて楽しかったです).\n","date":1645747200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645747200,"objectID":"d53228f62706d177c0e154f5efc0eea1","permalink":"https://syuntoku14.github.io/post/omron/","publishdate":"2022-02-25T00:00:00Z","relpermalink":"/post/omron/","section":"post","summary":"2021年6月から2022年2月まで, オムロンサイニックエックス (OSX) にて研究インターンをさせていただきました. これはOSXインターンについてまとめたポストになります. 元インターンの奥村さんのポストも参考になるのでぜひ.\n自己紹介  現在は奈良先端科学技術大学院大学の修士２年, 2022年の4月から東京大学で博士課程に進学予定の学生です. 学部の頃はロボットよりの研究をしていましたが, 修士課程では強化学習の理論やアルゴリズムがメインの研究をやっていました. 詳しくはホームページを見てね.  インターンまでの経緯 M2の前半で主著を1つ \u0026 共著を2つ生やすことができたので, M2の後半はインターンやりたいなあ〜って思っていたところ, 研究室経由でメンターの米谷さんからOSXインターンのお誘いをいただきました. 待遇や時期的にもかなり好条件だったので即返事をし, フルタイムで半年以上の研究インターンに参加させていただきました. インターンへの応募はここに詳細があります.\n何をやったのか 強化学習の理論と応用の実験をサポートしたライブラリ ShinRL を開発しました. 当初は米谷さんの提案でオフライン強化学習のテーマに取り組んでおり, 僕が個人的に開発していたShinRLを使ってデバッグ \u0026 アルゴリズムの実装を進めていました.","tags":["Research","Internship"],"title":"OMRON SINIC X (OSX) のインターン感想","type":"post"},{"authors":["Lingwei Zhu","Toshinori Kitamura","Matsubara Takamitsu"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645709127,"objectID":"a6700f544ef524edf272568133eed7c9","permalink":"https://syuntoku14.github.io/publication/zhu-2021-cautious-ac/","publishdate":"2022-02-24T13:25:39.083232Z","relpermalink":"/publication/zhu-2021-cautious-ac/","section":"publication","summary":"","tags":[],"title":"Cautious Actor-Critic","type":"publication"},{"authors":["Lingwei Zhu","Toshinori Kitamura","Takamitsu Matsubara"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645709304,"objectID":"ba63c75c3c8e4a836f02eb540c1e0855","permalink":"https://syuntoku14.github.io/publication/zhu-2021-cautious/","publishdate":"2022-02-24T13:28:26.469581Z","relpermalink":"/publication/zhu-2021-cautious/","section":"publication","summary":"","tags":[],"title":"Cautious Policy Programming: Exploiting KL Regularization in Monotonic Policy Improvement for Reinforcement Learning","type":"publication"},{"authors":["Toshinori Kitamura","Lingwei Zhu","Takamitsu Matsubara"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645709011,"objectID":"e5d8d35fc12c48660843119501bcca02","permalink":"https://syuntoku14.github.io/publication/kitamura-2021-geometric/","publishdate":"2022-02-24T13:23:31.052161Z","relpermalink":"/publication/kitamura-2021-geometric/","section":"publication","summary":"","tags":[],"title":"Geometric Value Iteration: Dynamic Error-Aware KL Regularization for Reinforcement Learning","type":"publication"},{"authors":["Toshinori Kitamura","Ryo Yonetani"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645709207,"objectID":"8f6d944d2cbecc87985ed40ed0134457","permalink":"https://syuntoku14.github.io/publication/kitamura-2021-shinrl/","publishdate":"2022-02-24T13:26:47.805697Z","relpermalink":"/publication/kitamura-2021-shinrl/","section":"publication","summary":"","tags":[],"title":"ShinRL: A Library for Evaluating RL Algorithms from Theoretical and Practical Perspectives","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://syuntoku14.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"c8d738e9720316240100a44b7bb7527d","permalink":"https://syuntoku14.github.io/project/fusion2urdf/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/fusion2urdf/","section":"project","summary":"A fusion360 add-in which converts fusion360 model to urdf(Universal Robotic Description Format) file.","tags":["Other"],"title":"fusion2urdf","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"9df5c858555e8cbf5fd3f5bd99bec599","permalink":"https://syuntoku14.github.io/project/rlil/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/rlil/","section":"project","summary":"A PyTorch Library for Building Reinforcement Learning and Imitation Learning Agents","tags":["Reinforcement Learning"],"title":"PyTorch-RL-IL (rlil)","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"0c8a6a37ff445156911643b3f7025748","permalink":"https://syuntoku14.github.io/project/shinrl/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/shinrl/","section":"project","summary":"A Library for Evaluating RL Algorithms from Theoretical and Practical Perspectives.","tags":["Reinforcement Learning"],"title":"ShinRL","type":"project"}]